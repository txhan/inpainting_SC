<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content=" We are the first to employ inpainting for semantic communication, selecting the most important parts of an image for transmission.We use a diffusion model to reconstruct high-quality images at the receiving end. This results in superior human-perceived image quality compared to other methods.">
  <meta property="og:title" content="Inpainting Based Highly Efficient Semantic Communication Approach"/>
  <meta property="og:description" content="We are the first to employ inpainting for semantic communication, selecting the most important parts of an image for transmission.We use a diffusion model to reconstruct high-quality images at the receiving end. This results in superior human-perceived image quality compared to other methods."/>
  <meta property="og:url" content="txhan.github.io/inpainting_SC"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_og_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Inpainting Based Highly Efficient Semantic Communication Approach">
  <meta name="twitter:description" content="We are the first to employ inpainting for semantic communication, selecting the most important parts of an image for transmission.We use a diffusion model to reconstruct high-quality images at the receiving end. This results in superior human-perceived image quality compared to other methods.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Semantic communication, Generative model, Image transmission">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Inpainting Based Highly Efficient Semantic Communication Approach</title>
  <link rel="icon" type="image/x-icon" href="static/images/fa.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://unpkg.com/js-image-zoom/js-image-zoom.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/js-image-zoom/js-image-zoom.min.js"></script>
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

   <script>
      function imageZoom(imgID, resultID) {
        var img, lens, result, cx, cy;
        img = document.getElementById(imgID);
        result = document.getElementById(resultID);
        /* Create lens: */
        lens = document.createElement("DIV");
        lens.setAttribute("class", "img-zoom-lens");
        /* Insert lens: */
        img.parentElement.insertBefore(lens, img);
        /* Calculate the ratio between result DIV and lens: */
        cx = result.offsetWidth / lens.offsetWidth;
        cy = result.offsetHeight / lens.offsetHeight;
        /* Set background properties for the result DIV */
        result.style.backgroundImage = "url('" + img.src + "')";
        result.style.backgroundSize = (img.width * cx) + "px " + (img.height * cy) + "px";
        /* Execute a function when someone moves the cursor over the image, or the lens: */
        lens.addEventListener("mousemove", moveLens);
        img.addEventListener("mousemove", moveLens);
        /* And also for touch screens: */
        lens.addEventListener("touchmove", moveLens);
        img.addEventListener("touchmove", moveLens);
        function moveLens(e) {
          var pos, x, y;
          /* Prevent any other actions that may occur when moving over the image */
          e.preventDefault();
          /* Get the cursor's x and y positions: */
          pos = getCursorPos(e);
          /* Calculate the position of the lens: */
          x = pos.x - (lens.offsetWidth / 2);
          y = pos.y - (lens.offsetHeight / 2);
          /* Prevent the lens from being positioned outside the image: */
          if (x > img.width - lens.offsetWidth) {x = img.width - lens.offsetWidth;}
          if (x < 0) {x = 0;}
          if (y > img.height - lens.offsetHeight) {y = img.height - lens.offsetHeight;}
          if (y < 0) {y = 0;}
          /* Set the position of the lens: */
          lens.style.left = x + "px";
          lens.style.top = y + "px";
          /* Display what the lens "sees": */
          result.style.backgroundPosition = "-" + (x * cx) + "px -" + (y * cy) + "px";
        }
        function getCursorPos(e) {
          var a, x = 0, y = 0;
          e = e || window.event;
          /* Get the x and y positions of the image: */
          a = img.getBoundingClientRect();
          /* Calculate the cursor's x and y coordinates, relative to the image: */
          x = e.pageX - a.left;
          y = e.pageY - a.top;
          /* Consider any page scrolling: */
          x = x - window.pageXOffset;
          y = y - window.pageYOffset;
          return {x : x, y : y};
        }
      }
    </script>
  
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Inpainting Based Highly Efficient Semantic Communication Approach</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=64S_qiAAAAAJ" target="_blank">Tianxiao Han</a>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=a2WEREUAAAAJ&hl=en" target="_blank">Qianqian Yang</a>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=MbmKROkAAAAJ&hl=en" target="_blank">Deniz Gunduz</a>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=7l8wsYgAAAAJ&hl=en&" target="_blank">Shi Zhiguo</a>
                    </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Zhejiang University & Imperial College London<br>ICASSP 2024 Generative Semantic Communication Track</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


          
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        Our main contributions are threefold: <br>
(i) We are the first to employ inpainting for semantic communication, selecting the most important parts of an image for transmission. This maintains a good balance between image quality and communication overhead.<br>
(ii) We use a diffusion model to reconstruct high-quality images at the receiving end. This results in superior human-perceived image quality compared to other methods.<br>
(iii) Our system exhibits robust performance under noisy conditions and can adapt to different types of images, which will help in further improving the model and reducing bias.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
This paper introduces an innovative approach to the semantic transmission of visual data over wireless networks, leveraging image inpainting to restore missing or distorted regions. At the transmitter, we utilize a novel pixel selection technique to detect and send semantically significant characteristics, increasing communication efficiency without compromising the quality of the image. At the receiver, we employ a blend of rapid inpainting methods with diffusion models (DDPM) to achieve high-definition image reconstruction. This combination results in outclassing traditional methods like Deep JSCC, particularly in terms of objective image quality and transmission efficiency. Against our previous generative method, while there is a slight decrease in data transmission, there are considerable improvements in objective evaluation metrics and a slight enhancement in the subjective ones. Notably, our approach obviates the need for predefined semantic segmentation models through the incorporation of traditional inpainting methods, thereby offering exceptional versatility across a wide array of applications. Moreover, the system exhibits robust performance even under high-noise environments. 
          </p>
          <p>
             <img src="static/images/aresults.png" alt="Additional Results" class="center-image blend-img-background"/>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-light">
  <div class="container is-full is-max-desktop">
    <div class="content ">
      <h2 class="title is-3">Abalation Study</h2>
      <div class="level-set has-text-justified">
        <p>
          In our ablation studies, we compare our results with those obtained when pixels are randomly selected at the transmitter for reconstruction. We can see a clear texture structure of our pixel selection result, while the random selection lose some semantic information.
        </p>
        <h2 class="has-text-centered">
          <emph>Move your mouse over the image to zoom</emph>
        </h2>
      </div>
    </div>
    <p>
      <div class="columns is-centered has-text-centered">
        <div class="column is-11">
          <div class="img-zoom-container">
            <img src="static/images/abalation.png" alt="abalation study" class="center-image blend-img-background" id="myimage"/> 

          </div>
        </div>
        <div class="column is-1">
          <div id="myresult" class="center-image img-zoom-result"></div>
        </div>
      </div>
      <script>
        imageZoom("myimage", "myresult");
      </script>
    </p>
  </div>
</section>

                    


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
